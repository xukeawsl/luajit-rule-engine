#!/usr/bin/env python3
"""
LuaJIT Rule Engine æ€§èƒ½æµ‹è¯•æŠ¥å‘Šç”Ÿæˆå™¨

ä» Google Benchmark çš„ JSON è¾“å‡ºç”Ÿæˆè¯¦ç»†çš„ HTML æŠ¥å‘Š
"""

import json
import os
import sys
from datetime import datetime
from pathlib import Path
import argparse
import re

# é¢œè‰²å®šä¹‰
COLORS = {
    'primary': '#3498db',
    'success': '#27ae60',
    'warning': '#f39c12',
    'danger': '#e74c3c',
    'info': '#16a085',
    'dark': '#2c3e50',
    'light': '#ecf0f1',
    'luajit': '#f39c12',
    'native': '#2980b9'
}

def load_json_results(results_dirs):
    """ä»å¤šä¸ªç›®å½•åŠ è½½ JSON æµ‹è¯•ç»“æœ"""
    results = {}

    # æ”¯æŒå¤šä¸ªç›®å½•
    if isinstance(results_dirs, str):
        results_dirs = [results_dirs]

    for results_dir in results_dirs:
        results_path = Path(results_dir)
        if not results_path.exists():
            continue

        for json_file in results_path.glob('*.json'):
            # è·³è¿‡æˆ‘ä»¬è‡ªå·±ç”Ÿæˆçš„æ‘˜è¦æ–‡ä»¶
            if 'benchmark_summary' in json_file.name or 'benchmark_report' in json_file.name:
                continue

            try:
                with open(json_file, 'r') as f:
                    data = json.load(f)

                    # åªå¤„ç†åŒ…å« benchmarks çš„æ–‡ä»¶
                    if 'benchmarks' not in data:
                        continue

                    benchmark_name = json_file.stem
                    results[benchmark_name] = data
                    print(f"  âœ“ åŠ è½½: {json_file.name} ({len(data['benchmarks'])} ä¸ªæµ‹è¯•)")
            except json.JSONDecodeError as e:
                print(f"  âœ— JSON è§£æé”™è¯¯ {json_file}: {e}")
            except Exception as e:
                print(f"  âœ— æ— æ³•åŠ è½½ {json_file}: {e}")

    return results

def parse_benchmark_name(name):
    """è§£æ benchmark åç§°ï¼Œæå–å…³é”®ä¿¡æ¯"""
    # æ ¼å¼: LuaJIT_SimpleRule_SmallData/iterations:1000000
    # æˆ–: Native_SimpleRule_SmallData/iterations:1000000

    parts = name.split('/')

    # è§£æä¸»åç§°
    main_name = parts[0]

    # æå–å®ç°ç±»å‹
    implementation = 'Unknown'
    if main_name.startswith('LuaJIT_'):
        implementation = 'LuaJIT'
    elif main_name.startswith('Native_'):
        implementation = 'Native'

    # æå–è§„åˆ™ç±»å‹å’Œæ•°æ®è§„æ¨¡
    # ä¾‹å¦‚: LuaJIT_SimpleRule_SmallData
    name_parts = main_name.split('_')
    rule_type = 'Unknown'
    data_size = 'Unknown'

    if len(name_parts) >= 3:
        if implementation == 'LuaJIT':
            rule_type = name_parts[1]  # SimpleRule
            data_size = name_parts[2] if len(name_parts) > 2 else ''  # SmallData
        elif implementation == 'Native':
            rule_type = name_parts[1]
            data_size = name_parts[2] if len(name_parts) > 2 else ''

    # æå–è¿­ä»£æ¬¡æ•°
    iterations = 0
    for part in parts:
        if part.startswith('iterations:'):
            iterations = int(part.split(':')[1])
            break

    return {
        'implementation': implementation,
        'rule_type': rule_type,
        'data_size': data_size,
        'iterations': iterations,
        'full_name': name
    }

def extract_comparison_data(benchmarks):
    """æå– LuaJIT vs Native å¯¹æ¯”æ•°æ®"""
    comparisons = {}

    for benchmark_name, data in benchmarks.items():
        if 'benchmarks' not in data:
            continue

        for bm in data['benchmarks']:
            info = parse_benchmark_name(bm['name'])

            # åªå¤„ç†æˆå¯¹çš„æµ‹è¯•
            if info['implementation'] == 'Unknown':
                continue

            # åˆ›å»ºé”®å€¼
            key = f"{info['rule_type']}_{info['data_size']}"

            if key not in comparisons:
                comparisons[key] = {
                    'rule_type': info['rule_type'],
                    'data_size': info['data_size'],
                    'luajit': None,
                    'native': None
                }

            # å­˜å‚¨æ•°æ®
            time_us = bm.get('real_time', 0)
            cpu_time_us = bm.get('cpu_time', 0)
            items_per_second = bm.get('items_per_second', 0)
            iterations = bm.get('iterations', 0)

            benchmark_data = {
                'time_us': time_us,
                'cpu_time_us': cpu_time_us,
                'items_per_second': items_per_second,
                'iterations': iterations,
                'name': bm['name']
            }

            if info['implementation'] == 'LuaJIT':
                comparisons[key]['luajit'] = benchmark_data
            elif info['implementation'] == 'Native':
                comparisons[key]['native'] = benchmark_data

    return comparisons

def calculate_speedup(luajit_time, native_time):
    """è®¡ç®—åŠ é€Ÿæ¯”"""
    if native_time == 0:
        return 0
    return luajit_time / native_time

def format_time(us):
    """æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º"""
    if us < 1:
        return f"{us*1000:.2f} ns"
    elif us < 1000:
        return f"{us:.2f} Î¼s"
    else:
        return f"{us/1000:.2f} ms"

def format_throughput(ops_per_sec):
    """æ ¼å¼åŒ–ååé‡"""
    if ops_per_sec >= 1e6:
        return f"{ops_per_sec/1e6:.2f}M ops/s"
    elif ops_per_sec >= 1e3:
        return f"{ops_per_sec/1e3:.2f}K ops/s"
    else:
        return f"{ops_per_sec:.0f} ops/s"

def get_recommendation(speedup, rule_type):
    """æ ¹æ®æ€§èƒ½æ¯”ç‡ç»™å‡ºå»ºè®®"""
    if speedup <= 1.2:
        return "LuaJIT", "success"  # æ¥è¿‘åŸç”Ÿæ€§èƒ½
    elif speedup <= 3.0:
        return "LuaJIT", "warning"  # å¯æ¥å—
    elif rule_type in ['SimpleRule']:
        return "Native", "warning"  # ç®€å•è§„åˆ™ç”¨ Native
    else:
        return "Native", "danger"  # æ€§èƒ½å·®è·å¤§

def generate_html_report(results, output_file):
    """ç”Ÿæˆ HTML æŠ¥å‘Š"""

    # æå–å¯¹æ¯”æ•°æ®
    comparisons = extract_comparison_data(results)

    # ç”Ÿæˆè¡¨æ ¼è¡Œ
    table_rows = []
    for key, data in sorted(comparisons.items()):
        if not data['luajit'] or not data['native']:
            continue

        luajit_time = data['luajit']['time_us']
        native_time = data['native']['time_us']
        speedup = calculate_speedup(luajit_time, native_time)

        recommendation, badge_type = get_recommendation(speedup, data['rule_type'])

        rule_label = data['rule_type'].replace('Rule', 'è§„åˆ™')
        data_label = data['data_size'].replace('Data', 'æ•°æ®')

        table_rows.append(f"""
                    <tr>
                        <td>{rule_label} + {data_label}</td>
                        <td><span class="badge badge-warning">{format_time(luajit_time)}</span><br><small>{format_throughput(data['luajit']['items_per_second'])}</small></td>
                        <td><span class="badge badge-success">{format_time(native_time)}</span><br><small>{format_throughput(data['native']['items_per_second'])}</small></td>
                        <td><strong>{speedup:.2f}x</strong><br>{"æ…¢" if speedup > 1 else "å¿«"}</td>
                        <td><span class="badge badge-{badge_type}">{recommendation}</span></td>
                    </tr>""")

    table_html = '\n'.join(table_rows)

    # æå–ç³»ç»Ÿä¿¡æ¯
    context = {}
    for data in results.values():
        if 'context' in data:
            context = data['context']
            break

    cpu_info = ""
    if context:
        num_cpus = context.get('num_cpus', 'N/A')
        mhz_per_cpu = context.get('mhz_per_cpu', 'N/A')
        cpu_info = f"{num_cpus} x {mhz_per_cpu} MHz"

    html = f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LuaJIT Rule Engine æ€§èƒ½æµ‹è¯•æŠ¥å‘Š</title>
    <style>
        * {{
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }}

        body {{
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: {COLORS['dark']};
            background: {COLORS['light']};
        }}

        .container {{
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }}

        header {{
            background: linear-gradient(135deg, {COLORS['primary']}, {COLORS['info']});
            color: white;
            padding: 40px 20px;
            border-radius: 10px;
            margin-bottom: 30px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }}

        header h1 {{
            font-size: 2.5em;
            margin-bottom: 10px;
        }}

        header .subtitle {{
            font-size: 1.1em;
            opacity: 0.9;
        }}

        .card {{
            background: white;
            border-radius: 10px;
            padding: 25px;
            margin-bottom: 25px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }}

        .card h2 {{
            color: {COLORS['primary']};
            margin-bottom: 20px;
            padding-bottom: 10px;
            border-bottom: 2px solid {COLORS['light']};
        }}

        table {{
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }}

        th, td {{
            padding: 12px;
            text-align: left;
            border-bottom: 1px solid #ddd;
        }}

        th {{
            background: {COLORS['light']};
            font-weight: 600;
            color: {COLORS['dark']};
        }}

        tr:hover {{
            background: #f8f9fa;
        }}

        .badge {{
            display: inline-block;
            padding: 4px 12px;
            border-radius: 20px;
            font-size: 0.85em;
            font-weight: 600;
        }}

        .badge-success {{
            background: {COLORS['success']};
            color: white;
        }}

        .badge-warning {{
            background: {COLORS['warning']};
            color: white;
        }}

        .badge-danger {{
            background: {COLORS['danger']};
            color: white;
        }}

        .findings {{
            background: #fff3cd;
            border-left: 4px solid {COLORS['warning']};
            padding: 15px 20px;
            margin: 20px 0;
            border-radius: 4px;
        }}

        .findings h3 {{
            color: #856404;
            margin-bottom: 10px;
        }}

        .recommendations {{
            background: #d1ecf1;
            border-left: 4px solid {COLORS['info']};
            padding: 15px 20px;
            margin: 20px 0;
            border-radius: 4px;
        }}

        .recommendations h3 {{
            color: #0c5460;
            margin-bottom: 10px;
        }}

        footer {{
            text-align: center;
            padding: 30px 20px;
            color: #7f8c8d;
            font-size: 0.9em;
        }}

        .progress-bar {{
            width: 100%;
            height: 25px;
            background: {COLORS['light']};
            border-radius: 12px;
            overflow: hidden;
            margin: 10px 0;
        }}

        .progress-fill {{
            height: 100%;
            background: linear-gradient(90deg, {COLORS['success']}, {COLORS['primary']});
            transition: width 0.3s ease;
            display: flex;
            align-items: center;
            justify-content: center;
            color: white;
            font-weight: 600;
            font-size: 0.9em;
        }}
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>ğŸš€ LuaJIT Rule Engine æ€§èƒ½æµ‹è¯•æŠ¥å‘Š</h1>
            <p class="subtitle">ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
        </header>

        <div class="card">
            <h2>ğŸ“Š æµ‹è¯•ç»“æœæ€»è§ˆ</h2>

            <h3 style="margin-top: 20px;">æ ¸å¿ƒæ€§èƒ½æŒ‡æ ‡å¯¹æ¯”</h3>
            <table>
                <thead>
                    <tr>
                        <th>è§„åˆ™ç±»å‹</th>
                        <th>LuaJIT æ€§èƒ½</th>
                        <th>Native æ€§èƒ½</th>
                        <th>æ€§èƒ½æ¯”ç‡</th>
                        <th>æ¨èæ–¹æ¡ˆ</th>
                    </tr>
                </thead>
                <tbody>
{table_html}
                </tbody>
            </table>
        </div>

        <div class="card">
            <h2>ğŸ¯ å…³é”®å‘ç°</h2>

            <div class="findings">
                <h3>æ ¸å¿ƒæ´å¯Ÿ</h3>
                <ul>
                    <li><strong>åŸºäºå®é™…æµ‹è¯•æ•°æ®</strong> - æœ¬æŠ¥å‘Šä» {len(results)} ä¸ªæµ‹è¯•ç»“æœæ–‡ä»¶ç”Ÿæˆ</li>
                    <li><strong>è‡ªåŠ¨åŒ–æ•°æ®æå–</strong> - ç›´æ¥ä» Google Benchmark JSON è¾“å‡ºè§£æ</li>
                    <li><strong>å¯¹æ¯”åˆ†æ</strong> - LuaJIT vs Native C++ æ€§èƒ½å¯¹æ¯”</li>
                </ul>
            </div>

            <div class="recommendations">
                <h3>å®è·µå»ºè®®</h3>
                <table>
                    <thead>
                        <tr>
                            <th>åœºæ™¯</th>
                            <th>æ¨èæ–¹æ¡ˆ</th>
                            <th>åŸå› </th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>é£æ§ç³»ç»Ÿ (ä¸­ç­‰å¤æ‚åº¦)</td>
                            <td><span class="badge badge-success">LuaJIT</span></td>
                            <td>æ€§èƒ½æ¥è¿‘åŸç”Ÿï¼Œå¯åŠ¨æ€æ›´æ–°è§„åˆ™</td>
                        </tr>
                        <tr>
                            <td>é…ç½®éªŒè¯ (ç®€å•è§„åˆ™)</td>
                            <td><span class="badge badge-warning">Native C++</span></td>
                            <td>æ€§èƒ½å…³é”®è·¯å¾„ï¼Œè¿½æ±‚æè‡´æ€§èƒ½</td>
                        </tr>
                        <tr>
                            <td>ç»¼åˆè¯„åˆ† (è¶…å¤æ‚)</td>
                            <td><span class="badge badge-warning">æ‹†åˆ† + LuaJIT</span></td>
                            <td>æˆ–ç›´æ¥ä½¿ç”¨ Native C++</td>
                        </tr>
                        <tr>
                            <td>å¿«é€ŸåŸå‹å¼€å‘</td>
                            <td><span class="badge badge-success">LuaJIT</span></td>
                            <td>çµæ´»æ€§ä¸å¼€å‘é€Ÿåº¦ > æ€§èƒ½</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="card">
            <h2>ğŸ“ˆ è¯¦ç»†æµ‹è¯•æ•°æ®</h2>
            <p>ä»¥ä¸‹æ˜¯ä» Google Benchmark ç”Ÿæˆçš„åŸå§‹æ•°æ®æ‘˜è¦ï¼š</p>

            <h4 style="margin-top: 20px;">æ‰€æœ‰åŸºå‡†æµ‹è¯•ç»“æœ</h4>
            <table>
                <thead>
                    <tr>
                        <th>æµ‹è¯•åç§°</th>
                        <th>æ—¶é—´ (Î¼s/op)</th>
                        <th>CPU (Î¼s/op)</th>
                        <th>è¿­ä»£æ¬¡æ•°</th>
                        <th>ååé‡</th>
                    </tr>
                </thead>
                <tbody>
"""

    # æ·»åŠ æ‰€æœ‰æµ‹è¯•çš„è¯¦ç»†æ•°æ®
    for benchmark_name, data in sorted(results.items()):
        if 'benchmarks' not in data:
            continue

        for bm in data['benchmarks']:
            name = bm['name']
            time_us = bm.get('real_time', 0)
            cpu_time_us = bm.get('cpu_time', 0)
            iterations = bm.get('iterations', 0)
            items_per_sec = bm.get('items_per_second', 0)

            html += f"""
                    <tr>
                        <td>{name}</td>
                        <td>{time_us:.2f}</td>
                        <td>{cpu_time_us:.2f}</td>
                        <td>{iterations:,}</td>
                        <td>{format_throughput(items_per_sec)}</td>
                    </tr>"""

    html += """
                </tbody>
            </table>
        </div>

        <footer>
            <p>Generated by LuaJIT Rule Engine Benchmark Tool</p>
            <p>æµ‹è¯•ç¯å¢ƒ: """ + cpu_info + """</p>
            <p>æµ‹è¯•æ—¶é—´: """ + datetime.now().strftime('%Y-%m-%d %H:%M:%S') + """</p>
        </footer>
    </div>
</body>
</html>
"""

    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(html)

    print(f"âœ… HTML æŠ¥å‘Šå·²ç”Ÿæˆ: {output_file}")

def generate_markdown_report(results, output_file):
    """ç”Ÿæˆ Markdown æŠ¥å‘Š"""

    # æå–å¯¹æ¯”æ•°æ®
    comparisons = extract_comparison_data(results)

    md = f"""# LuaJIT Rule Engine æ€§èƒ½æµ‹è¯•æŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

---

## ğŸ“Š æ‰§è¡Œæ‘˜è¦

æœ¬æŠ¥å‘Šä» **{len(results)}** ä¸ªæµ‹è¯•ç»“æœæ–‡ä»¶è‡ªåŠ¨ç”Ÿæˆï¼ŒåŒ…å«ä»¥ä¸‹æµ‹è¯•ï¼š

"""

    # ç»Ÿè®¡ä¿¡æ¯
    total_tests = sum(len(data.get('benchmarks', [])) for data in results.values())
    md += f"- **æ€»æµ‹è¯•æ•°**: {total_tests}\n"
    md += f"- **æµ‹è¯•æ–‡ä»¶**: {', '.join(sorted(results.keys()))}\n\n"

    md += "---\n\n"

    # ç”Ÿæˆå¯¹æ¯”è¡¨æ ¼
    md += "## ğŸ¯ æ ¸å¿ƒæ€§èƒ½æŒ‡æ ‡\n\n"
    md += "| è§„åˆ™ç±»å‹ | æ•°æ®è§„æ¨¡ | LuaJIT æ€§èƒ½ | Native æ€§èƒ½ | æ€§èƒ½æ¯”ç‡ | æ¨èæ–¹æ¡ˆ |\n"
    md += "|---------|---------|------------|------------|---------|---------|\n"

    for key, data in sorted(comparisons.items()):
        if not data['luajit'] or not data['native']:
            continue

        luajit_time = data['luajit']['time_us']
        native_time = data['native']['time_us']
        speedup = calculate_speedup(luajit_time, native_time)
        recommendation, _ = get_recommendation(speedup, data['rule_type'])

        rule_label = data['rule_type'].replace('Rule', '')
        data_label = data['data_size'].replace('Data', '')

        md += f"| {rule_label} | {data_label} | {format_time(luajit_time)} | {format_time(native_time)} | {speedup:.2f}x | {recommendation} |\n"

    md += "\n---\n\n"

    # å…³é”®å‘ç°
    md += "## ğŸ” å…³é”®å‘ç°\n\n"

    best_speedup = min(
        (calculate_speedup(d['luajit']['time_us'], d['native']['time_us'])
         for d in comparisons.values() if d['luajit'] and d['native']),
        default=0
    )

    worst_speedup = max(
        (calculate_speedup(d['luajit']['time_us'], d['native']['time_us'])
         for d in comparisons.values() if d['luajit'] and d['native']),
        default=0
    )

    md += f"- **æœ€ä½³æ€§èƒ½æ¯”ç‡**: {best_speedup:.2f}x (æ¥è¿‘åŸç”Ÿæ€§èƒ½)\n"
    md += f"- **æœ€å¤§æ€§èƒ½å·®è·**: {worst_speedup:.2f}x\n"
    md += f"- **æµ‹è¯•è¦†ç›–**: {len(comparisons)} ç§è§„åˆ™/æ•°æ®ç»„åˆ\n\n"

    md += "---\n\n"

    # è¯¦ç»†æµ‹è¯•æ•°æ®
    md += "## ğŸ“ˆ è¯¦ç»†æµ‹è¯•æ•°æ®\n\n"

    for benchmark_name, data in sorted(results.items()):
        if 'benchmarks' not in data:
            continue

        md += f"### {benchmark_name}\n\n"
        md += "| æµ‹è¯•åç§° | æ—¶é—´ (Î¼s/op) | CPU (Î¼s/op) | è¿­ä»£æ¬¡æ•° | ååé‡ |\n"
        md += "|---------|-------------|------------|---------|--------|\n"

        for bm in data['benchmarks']:
            name = bm['name']
            time_us = bm.get('real_time', 0)
            cpu_time_us = bm.get('cpu_time', 0)
            iterations = bm.get('iterations', 0)
            items_per_sec = bm.get('items_per_second', 0)

            md += f"| {name} | {time_us:.2f} | {cpu_time_us:.2f} | {iterations:,} | {format_throughput(items_per_sec)} |\n"

        md += "\n"

    md += "---\n\n"

    md += f"""**æŠ¥å‘Šç‰ˆæœ¬**: 1.0
**æœ€åæ›´æ–°**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""

    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(md)

    print(f"âœ… Markdown æŠ¥å‘Šå·²ç”Ÿæˆ: {output_file}")

def generate_json_summary(results, output_file):
    """ç”Ÿæˆ JSON æ ¼å¼çš„æ‘˜è¦"""

    comparisons = extract_comparison_data(results)

    summary = {
        "generated_at": datetime.now().isoformat(),
        "source_files": list(results.keys()),
        "total_benchmarks": sum(len(data.get('benchmarks', [])) for data in results.values()),
        "benchmarks": {}
    }

    for key, data in comparisons.items():
        if not data['luajit'] or not data['native']:
            continue

        rule_key = data['rule_type'].lower().replace('rule', '_rule')
        summary["benchmarks"][rule_key] = {
            "luajit_us": round(data['luajit']['time_us'], 2),
            "native_us": round(data['native']['time_us'], 2),
            "speedup": round(calculate_speedup(data['luajit']['time_us'], data['native']['time_us']), 2),
            "luajit_throughput": round(data['luajit']['items_per_second'], 0),
            "native_throughput": round(data['native']['items_per_second'], 0),
            "recommendation": get_recommendation(
                calculate_speedup(data['luajit']['time_us'], data['native']['time_us']),
                data['rule_type']
            )[0]
        }

    # æå–ç³»ç»Ÿä¸Šä¸‹æ–‡
    for data in results.values():
        if 'context' in data:
            summary["context"] = {
                "date": data['context'].get('date'),
                "host_name": data['context'].get('host_name'),
                "num_cpus": data['context'].get('num_cpus'),
                "mhz_per_cpu": data['context'].get('mhz_per_cpu'),
                "cpu_scaling_enabled": data['context'].get('cpu_scaling_enabled'),
            }
            break

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)

    print(f"âœ… JSON æ‘˜è¦å·²ç”Ÿæˆ: {output_file}")

def main():
    parser = argparse.ArgumentParser(description='ç”Ÿæˆæ€§èƒ½æµ‹è¯•æŠ¥å‘Š')
    parser.add_argument('--results-dir',
                       nargs='+',
                       default=['build/benchmarks/results', 'benchmarks/results'],
                       help='æµ‹è¯•ç»“æœç›®å½• (é»˜è®¤: build/benchmarks/results benchmarks/results)')
    parser.add_argument('--output-dir',
                       default='benchmarks/results',
                       help='æŠ¥å‘Šè¾“å‡ºç›®å½• (é»˜è®¤: benchmarks/results)')
    parser.add_argument('--format',
                       choices=['html', 'markdown', 'json', 'all'],
                       default='all',
                       help='æŠ¥å‘Šæ ¼å¼ (é»˜è®¤: all)')

    args = parser.parse_args()

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    # åŠ è½½æµ‹è¯•ç»“æœ
    print("ğŸ“Š æ­£åœ¨ç”Ÿæˆæ€§èƒ½æµ‹è¯•æŠ¥å‘Š...")
    print(f"   æœç´¢ç›®å½•: {args.results_dir}")
    results = load_json_results(args.results_dir)

    if not results:
        print("âŒ æœªæ‰¾åˆ°æµ‹è¯•ç»“æœï¼")
        print("\nğŸ’¡ è¯·å…ˆè¿è¡Œ benchmark æµ‹è¯•:")
        print("   cd build/benchmarks")
        print("   ./basic_benchmark --benchmark_format=json > results/basic.json")
        print("   ./comparison_benchmark --benchmark_format=json > results/comparison.json")
        return 1

    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

    # ç”ŸæˆæŠ¥å‘Š
    if args.format in ['html', 'all']:
        html_file = output_dir / f"benchmark_report_{timestamp}.html"
        generate_html_report(results, html_file)

    if args.format in ['markdown', 'all']:
        md_file = output_dir / f"benchmark_report_{timestamp}.md"
        generate_markdown_report(results, md_file)

    if args.format in ['json', 'all']:
        json_file = output_dir / f"benchmark_summary_{timestamp}.json"
        generate_json_summary(results, json_file)

    print(f"\nâœ… æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼è¾“å‡ºç›®å½•: {output_dir}")
    print(f"\nğŸ’¡ æŸ¥çœ‹æŠ¥å‘Š:")
    print(f"   HTML:     {output_dir}/benchmark_report_{timestamp}.html")
    print(f"   Markdown: {output_dir}/benchmark_report_{timestamp}.md")
    print(f"   JSON:     {output_dir}/benchmark_summary_{timestamp}.json")

    return 0

if __name__ == '__main__':
    sys.exit(main())
